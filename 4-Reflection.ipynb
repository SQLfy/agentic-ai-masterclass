{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16f2ecf-82e7-479c-8d76-4af5702e8b71",
   "metadata": {},
   "source": [
    "# Exercise 4 - Reflection pattern implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e179dbd0-c430-4807-88e8-86a31cbe5ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your open ai key in .env file (text file) as OPENAI_API_KEY=your-key\n",
    "# your .env file should be in tthe same directory as this file\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c3a1b3-dee3-4eb1-b2cd-5d7546d89d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# --- Setup LLM (Assumes you have OPENAI_API_KEY set) ---\n",
    "# You can swap this for Anthropic, Llama, etc.\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
    "\n",
    "# --- 1. Define the State ---\n",
    "class WritingState(TypedDict):\n",
    "    topic: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    revision_count: int\n",
    "\n",
    "# --- 2. Define the PROMPTS (The \"Brains\") ---\n",
    "\n",
    "WRITER_PROMPT = \"\"\"\n",
    "You are a technical content writer. \n",
    "If this is the first draft, write a short, engaging blog post about the topic: {topic}.\n",
    "If you have received feedback, rewrite the draft to address the critique below.\n",
    "\n",
    "Current Critique: {critique}\n",
    "\"\"\"\n",
    "\n",
    "# This is the \"Reflector\" logic you asked for\n",
    "REFLECTOR_PROMPT = \"\"\"\n",
    "You are a Senior Technical Editor. Your job is to critique the following blog post.\n",
    "You must be strict but helpful. \n",
    "\n",
    "Check for:\n",
    "1. Technical Accuracy (Are the terms used correctly?)\n",
    "2. Clarity (Is it easy to read?)\n",
    "3. Engagement (Is it boring?)\n",
    "\n",
    "If the post is excellent and ready to publish, reply with exactly one word: FINISH.\n",
    "Otherwise, provide a numbered list of specific actionable changes the writer should make.\n",
    "\"\"\"\n",
    "\n",
    "# --- 3. Define the Nodes ---\n",
    "\n",
    "def writer_node(state: WritingState):\n",
    "    print(f\"\\n--- WRITER: Working on draft {state['revision_count'] + 1} ---\")\n",
    "    \n",
    "    # Construct the message history\n",
    "    messages = [\n",
    "        SystemMessage(content=WRITER_PROMPT.format(topic=state['topic'], critique=state.get('critique', 'None'))),\n",
    "        HumanMessage(content=state.get('draft', f\"Write a blog about {state['topic']}\"))\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    return {\n",
    "        \"draft\": response.content, \n",
    "        \"revision_count\": state[\"revision_count\"] + 1\n",
    "    }\n",
    "\n",
    "def reflector_node(state: WritingState):\n",
    "    print(\"\\n--- REFLECTOR: Reviewing draft... ---\")\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTOR_PROMPT),\n",
    "        HumanMessage(content=state['draft'])\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    print(f\"Reflector Feedback: {response.content[:100]}...\") # Print preview of feedback\n",
    "    return {\"critique\": response.content}\n",
    "\n",
    "# --- 4. Define the Logic (The Router) ---\n",
    "\n",
    "def should_continue(state: WritingState):\n",
    "    critique = state[\"critique\"]\n",
    "    revision_count = state[\"revision_count\"]\n",
    "    \n",
    "    # Stop if the editor is happy OR if we've tried 3 times (safety valve)\n",
    "    if \"FINISH\" in critique or revision_count >= 3:\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"writer\" # Loop back\n",
    "\n",
    "# --- 5. Build the Graph ---\n",
    "\n",
    "builder = StateGraph(WritingState)\n",
    "\n",
    "builder.add_node(\"writer\", writer_node)\n",
    "builder.add_node(\"reflector\", reflector_node)\n",
    "\n",
    "builder.add_edge(START, \"writer\")\n",
    "builder.add_edge(\"writer\", \"reflector\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"reflector\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"writer\": \"writer\",  # The Loop\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "app = builder.compile()\n",
    "\n",
    "# --- 6. Run it ---\n",
    "print(\">>> STARTING BLOG AGENT\")\n",
    "initial_state = {\n",
    "    \"topic\": \"The importance of 'Reflection' in Agentic AI\",\n",
    "    \"draft\": \"\",\n",
    "    \"critique\": \"\",\n",
    "    \"revision_count\": 0\n",
    "}\n",
    "\n",
    "# This will loop until the Reflector says \"FINISH\"\n",
    "final_output = app.invoke(initial_state)\n",
    "\n",
    "print(\"\\n\\n>>> FINAL RESULT <<<\")\n",
    "print(final_output[\"draft\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdcfaf6-10f3-43da-a82b-bcb4626e9822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
